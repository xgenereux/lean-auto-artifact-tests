# Dataset Documentation

This directory contains two Parquet datasets with performance statistics for Aesop tactics evaluated on Lean/Mathlib theorems.

## Running Python Scripts

To run Python scripts in this project, either:
- Activate the virtual environment: `source .venv/bin/activate`
- Or use: `uv run <script>.py`

All scripts accept command-line arguments. Use `--help` for details:
- `./collect_aesopstats.py <data_dir> <output_dir>` - Collects aesopstats from JSONL files
- `./collect_results.py <data_dir> <output_dir>` - Collects results from .result files
- `./analyze.py <input_dir> <output_dir>` - Analyzes the datasets and generates plots

## aesopstats.parquet

Generated by `collect_aesopstats.py` from `**/*.aesopstats.*.jsonl` files in the data directory.

### Structure
- **Index**: Multi-index with `(tactic, declaration)`
- **Rows**: ~600k records
- **One row per**: Tactic execution on a specific declaration

### Columns

**Timing metrics** (all in nanoseconds):
- `total`: Total execution time
- `search`: Search time
- `script`: Script execution time
- `ruleSetConstruction`: Rule set construction time
- `ruleSelection`: Rule selection time
- `forwardState`: Forward state time
- `configParsing`: Config parsing time
- `rpinf`: RPINF computation time

**Metadata**:
- `syntax`: The actual tactic syntax used (string)
- `file`: Source file path (string)
- `goalSolved`: Whether the goal was solved (boolean)
- `ruleStats`: Array of dicts with detailed rule execution statistics
  - Each entry contains: `elapsed`, `rule` (with `builder`, `name`, `phase`, etc.), `successful`
- `goalStats`: Array of dicts with per-goal statistics (~300k non-empty arrays)
  - Each entry contains: `goalId`, `goalKind`, `lctxSize`, `forwardStateStats`
- `scriptGenerated`, `position`: Always null

**Tactics** (6 variants):
- `useSaturateNewDAss` (147,621 rows)
- `useSaturateOldDAs` (147,237 rows)
- `useAesopWithPremises` (81,547 rows)
- `useAesop` (80,332 rows)
- `useAesopPUnsafeOld` (77,607 rows)
- `useAesopPUnsafeNew` (77,473 rows)

### ruleStats Structure
`ruleStats` is a numpy array of dicts. Each dict contains:
```python
{
    'elapsed': int,  # nanoseconds
    'rule': {
        'builder': str,  # e.g., 'forward', 'apply', etc.
        'name': str,
        'phase': str,
        'rendered': str,
        'scope': str
    },
    'successful': bool
}
```

### goalStats Structure
`goalStats` is a numpy array of dicts. Each dict contains:
```python
{
    'goalId': int,
    'goalKind': str,  # e.g., 'postNorm'
    'lctxSize': int,  # local context size
    'forwardStateStats': {
        'ruleStateStats': [  # array of dicts
            {
                'ruleName': {
                    'builder': str,  # e.g., 'forward'
                    'name': str,
                    'phase': str,
                    'rendered': str,
                    'scope': str
                },
                'clusterStateStats': [  # array of dicts
                    {
                        'slots': int,
                        'instantiationStats': [  # array of dicts
                            {
                                'hyps': int,  # number of hypotheses
                                'matches': int  # number of matches
                            }
                        ]
                    }
                ]
            }
        ]
    }
}
```

**Note**: `instantiationStats` data is only available in the new forward reasoning implementation (`useAesopPUnsafeNew`, `useAesopWithPremises`, `useSaturateNewDAss`). Old tactics (`useAesopPUnsafeOld`, `useSaturateOldDAs`) have empty `instantiationStats` arrays.

## gatheredresult.parquet

Generated by `collect_results.py` from `**/*.result` files in the data directory.

### Structure
- **Index**: Multi-index with `(tactic, declaration)`
- **Rows**: 877,545 records (175,509 declarations Ã— 5 tactics)
- **One row per**: Tactic evaluation on a specific declaration

### Columns
- `success`: Whether the tactic succeeded (boolean)
- `time`: Elapsed time in milliseconds (int)

**Tactics** (5 variants, in order):
1. `testUnknownConstant` - Test for unknown constants (141,613 successful)
2. `useAesopPUnsafeNew` - New unsafe Aesop variant (45,861 successful)
3. `useAesopPUnsafeOld` - Old unsafe Aesop variant
4. `useSaturateNewDAss` - New saturation variant (13,120 successful)
5. `useSaturateOldDAs` - Old saturation variant

### Key Statistics
- `testUnknownConstant` success rate: 80.7% (141,613 / 175,509)
- `useSaturateNewDAss` success rate: 7.5% (13,120 / 175,509)
- `useAesopPUnsafeNew` success rate: 26.1% (45,861 / 175,509)

### Notes
- Declaration names have trailing periods stripped for consistency with aesopstats.parquet
- `testUnknownConstant` is a validity check; if it fails, the theorem may have issues
- Times are in milliseconds (unlike aesopstats which uses nanoseconds)
